{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from collections import deque\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 60  \n",
    "FUTURE_PERIOD_PREDICT = 3  \n",
    "RATIO_TO_PREDICT = \"LTC-USD\"\n",
    "\n",
    "\n",
    "def classify(current, future):\n",
    "    if float(future) > float(current):  \n",
    "        return 1\n",
    "    else:  \n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "    df = df.drop(\"future\", 1)  \n",
    "\n",
    "    for col in df.columns:  \n",
    "        if col != \"target\":  \n",
    "            df[col] = df[col].pct_change()  \n",
    "            df.dropna(inplace=True)  \n",
    "            df[col] = preprocessing.scale(df[col].values)  # scale between 0 and 1.\n",
    "\n",
    "    df.dropna(inplace=True)  # cleanup again... jic.\n",
    "\n",
    "\n",
    "    sequential_data = []  # this is a list that will CONTAIN the sequences\n",
    "    prev_days = deque(maxlen=SEQ_LEN)  # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n",
    "\n",
    "    for i in df.values:  # iterate over the values\n",
    "        prev_days.append([n for n in i[:-1]])  # store all but the target\n",
    "        if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n",
    "            sequential_data.append([np.array(prev_days), i[-1]])  # append those bad boys!\n",
    "\n",
    "    random.shuffle(sequential_data)  # shuffle for good measure.\n",
    "\n",
    "    buys = []  # list that will store our buy sequences and targets\n",
    "    sells = []  # list that will store our sell sequences and targets\n",
    "\n",
    "    for seq, target in sequential_data:  # iterate over the sequential data\n",
    "        if target == 0:  # if it's a \"not buy\"\n",
    "            sells.append([seq, target])  # append to sells list\n",
    "        elif target == 1:  # otherwise if the target is a 1...\n",
    "            buys.append([seq, target])  # it's a buy!\n",
    "\n",
    "    random.shuffle(buys)  # shuffle the buys\n",
    "    random.shuffle(sells)  # shuffle the sells!\n",
    "\n",
    "    lower = min(len(buys), len(sells))  # what's the shorter length?\n",
    "\n",
    "    buys = buys[:lower]  # make sure both lists are only up to the shortest length.\n",
    "    sells = sells[:lower]  # make sure both lists are only up to the shortest length.\n",
    "\n",
    "    sequential_data = buys+sells  # add them together\n",
    "    random.shuffle(sequential_data)  # another shuffle, so the model doesn't get confused with all 1 class then the other.\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for seq, target in sequential_data:  # going over our new sequential data\n",
    "        X.append(seq)  # X is the sequences\n",
    "        y.append(target)  # y is the targets/labels (buys vs sell/notbuy)\n",
    "\n",
    "    return np.asarray(X), y  # return X and y...and make X a numpy array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: 77922 validation: 3860\n",
      "Dont buys: 38961, buys: 38961\n",
      "VALIDATION Dont buys: 1930, buys: 1930\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"crypto_data/LTC-USD.csv\", names=['time', 'low', 'high', 'open', 'close', 'volume'])\n",
    "\n",
    "main_df = pd.DataFrame() # begin empty\n",
    "\n",
    "ratios = [\"BTC-USD\", \"LTC-USD\", \"BCH-USD\", \"ETH-USD\"]  # the 4 ratios we want to consider\n",
    "for ratio in ratios:  # begin iteration\n",
    "\n",
    "    ratio = ratio.split('.csv')[0]  # split away the ticker from the file-name\n",
    "    dataset = f'crypto_data/{ratio}.csv'  # get the full path to the file.\n",
    "    df = pd.read_csv(dataset, names=['time', 'low', 'high', 'open', 'close', 'volume'])  # read in specific file\n",
    "\n",
    "    # rename volume and close to include the ticker so we can still which close/volume is which:\n",
    "    df.rename(columns={\"close\": f\"{ratio}_close\", \"volume\": f\"{ratio}_volume\"}, inplace=True)\n",
    "\n",
    "    df.set_index(\"time\", inplace=True)  # set time as index so we can join them on this shared time\n",
    "    df = df[[f\"{ratio}_close\", f\"{ratio}_volume\"]]  # ignore the other columns besides price and volume\n",
    "\n",
    "    if len(main_df)==0:  # if the dataframe is empty\n",
    "        main_df = df  # then it's just the current df\n",
    "    else:  # otherwise, join this data to the main one\n",
    "        main_df = main_df.join(df)\n",
    "\n",
    "main_df.fillna(method=\"ffill\", inplace=True)  # if there are gaps in data, use previously known values\n",
    "main_df.dropna(inplace=True)\n",
    "#print(main_df.head())  # how did we do??\n",
    "\n",
    "main_df['future'] = main_df[f'{RATIO_TO_PREDICT}_close'].shift(-FUTURE_PERIOD_PREDICT)\n",
    "main_df['target'] = list(map(classify, main_df[f'{RATIO_TO_PREDICT}_close'], main_df['future']))\n",
    "\n",
    "main_df.dropna(inplace=True)\n",
    "\n",
    "## here, split away some slice of the future data from the main main_df.\n",
    "times = sorted(main_df.index.values)\n",
    "last_5pct = sorted(main_df.index.values)[-int(0.05*len(times))]\n",
    "\n",
    "validation_main_df = main_df[(main_df.index >= last_5pct)]\n",
    "main_df = main_df[(main_df.index < last_5pct)]\n",
    "\n",
    "train_x, train_y = preprocess_df(main_df)\n",
    "validation_x, validation_y = preprocess_df(validation_main_df)\n",
    "\n",
    "print(f\"train data: {len(train_x)} validation: {len(validation_x)}\")\n",
    "print(f\"Dont buys: {train_y.count(0)}, buys: {train_y.count(1)}\")\n",
    "print(f\"VALIDATION Dont buys: {validation_y.count(0)}, buys: {validation_y.count(1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "EPOCHS = 3  \n",
    "BATCH_SIZE = 34 \n",
    "NAME = f\"{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.python.framework import ops\n",
    "from keras.optimizers import RMSprop\n",
    "#from tensorflow.keras.callbacks import TensorBoard\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dhrupal\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dhrupal\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dhrupal\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dhrupal\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dhrupal\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\dhrupal\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dhrupal\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dhrupal\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\dhrupal\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dhrupal\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dhrupal\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 77922 samples, validate on 3860 samples\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\dhrupal\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dhrupal\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dhrupal\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dhrupal\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\dhrupal\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "35326/77922 [============>.................] - ETA: 9:47 - loss: 0.7328 - acc: 0.5153"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(train_x.shape[1:]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())  #normalizes activation outputs, same reason you want to normalize your input data.\n",
    "\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['acc']\n",
    ")\n",
    "\n",
    "#tboard_log_dir = os.path.join(\"logs\",NAME)\n",
    "#tensorboard = TensorBoard(log_dir = tboard_log_dir)\n",
    "#filepath = \"RNN_Final-{epoch:02d}-{val_acc:.3f}\"  # unique file name that will include the epoch and the validation acc for that epoch\n",
    "#checkpoint = ModelCheckpoint(\"./models/{}.model\".format(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')) # saves only the best ones\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_x, np.reshape(train_y,(np.shape(train_y)[0],1)),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(validation_x, np.reshape(validation_y,(np.shape(validation_y)[0],1))),\n",
    "    #callbacks=[tensorboard, checkpoint],\n",
    ")\n",
    "\n",
    "# Score model\n",
    "score = model.evaluate(validation_x, validation_y, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "# Save model\n",
    "model.save(\"./models/{}\".format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 2.07374472e-02, -5.64979506e-02,  3.79690673e-03, ...,\n",
       "         -5.79715810e-03,  4.32983884e-03, -3.31029505e-02],\n",
       "        [ 1.29893697e-01, -8.48365589e-02,  3.79690673e-03, ...,\n",
       "         -5.79715810e-03, -1.61262646e-02, -5.43027249e-02],\n",
       "        [-8.08854814e-04, -5.08378576e-02,  3.79690673e-03, ...,\n",
       "         -5.79715810e-03,  2.47864299e-02, -4.55235434e-02],\n",
       "        ...,\n",
       "        [ 7.71379303e-04, -8.79929531e-02, -1.53871313e+00, ...,\n",
       "         -5.80016052e-03, -6.10918390e-01, -5.41009930e-02],\n",
       "        [-8.08854814e-04, -7.82608225e-02,  3.79690673e-03, ...,\n",
       "         -5.77007864e-03,  4.32983884e-03,  2.22037283e-02],\n",
       "        [-2.11955990e-01,  4.27117487e-01,  5.18992920e-01, ...,\n",
       "         -5.84787915e-03, -1.61487561e-02, -5.60084164e-03]],\n",
       "\n",
       "       [[-2.20761279e-03, -7.77095309e-02, -2.69048980e-01, ...,\n",
       "         -4.69931246e-03, -7.70906310e-01, -4.78111554e-02],\n",
       "        [-1.24397861e+00, -2.27657834e-02, -7.24084120e-01, ...,\n",
       "         -5.74259132e-03, -1.33091450e+00, -3.11379665e-02],\n",
       "        [ 3.96283670e-01, -7.44183732e-02, -5.42572643e-01, ...,\n",
       "         -5.87482024e-03, -1.02580057e+00,  5.24598450e-03],\n",
       "        ...,\n",
       "        [-6.51075657e-01, -7.35693951e-02, -1.27098321e+00, ...,\n",
       "         -5.88220029e-03,  4.32983884e-03,  1.26289532e-02],\n",
       "        [ 1.76810548e-02, -6.73347713e-02,  4.59769487e-01, ...,\n",
       "         -2.39582280e-03,  4.32983884e-03, -4.98992132e-02],\n",
       "        [-2.19897146e-03,  8.70614439e-02, -1.18112950e+00, ...,\n",
       "         -5.88653265e-03,  2.23870324e-02, -5.20442890e-02]],\n",
       "\n",
       "       [[-8.08854814e-04, -8.08308308e-02, -9.80669140e-02, ...,\n",
       "         -5.87733891e-03, -1.55727790e-02, -4.92720341e-02],\n",
       "        [-8.08854814e-04, -7.06266587e-02,  2.07540444e-01, ...,\n",
       "         -4.06107084e-03,  5.82689913e-01,  2.15859293e-02],\n",
       "        [ 6.87328099e-04, -4.63799533e-02,  3.09237261e-01, ...,\n",
       "         -5.69496119e-03,  2.42812993e-02, -5.08266440e-02],\n",
       "        ...,\n",
       "        [-2.37146086e-03, -2.46039409e-02,  1.05077543e-01, ...,\n",
       "         -5.76388807e-03,  4.32983884e-03, -4.00420938e-02],\n",
       "        [-3.85955230e-03, -7.56351262e-02, -8.06122358e-01, ...,\n",
       "         -5.87791337e-03, -1.74148270e-01, -4.07100863e-02],\n",
       "        [-9.07562039e-01, -2.49135604e-02, -1.00959808e+00, ...,\n",
       "         -2.22025943e-03,  4.32983884e-03, -4.67371353e-02]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-2.30236812e-03, -6.35874534e-02, -2.80586845e-01, ...,\n",
       "         -3.23519108e-03, -1.41190317e-02, -4.87856792e-02],\n",
       "        [-8.08854814e-04, -4.46514687e-02,  3.79690673e-03, ...,\n",
       "         -5.33813523e-03, -3.28442879e-01, -3.71180863e-02],\n",
       "        [ 6.84660389e-04, -6.35282304e-02, -1.85828423e-01, ...,\n",
       "         -5.87179176e-03, -1.25149965e-01, -5.02308303e-02],\n",
       "        ...,\n",
       "        [-8.08854814e-04, -7.71275493e-02, -7.55961469e-01, ...,\n",
       "         -4.64898079e-03,  4.32983884e-03, -4.60015344e-02],\n",
       "        [-3.06538216e-01, -6.19182002e-03,  3.79690673e-03, ...,\n",
       "         -5.66435663e-03, -1.81362401e-01, -5.04084931e-03],\n",
       "        [-2.30211930e-03, -3.80491683e-02,  9.88740911e-02, ...,\n",
       "         -4.93443026e-03,  2.29205402e-02, -5.36411910e-02]],\n",
       "\n",
       "       [[-8.08854814e-04, -4.27858348e-02,  3.79690673e-03, ...,\n",
       "         -5.87794107e-03,  4.32983884e-03, -4.93999507e-02],\n",
       "        [-8.08854814e-04, -2.18871250e-02,  9.97261670e-02, ...,\n",
       "         -5.86628475e-03, -1.68514974e+00, -4.69466866e-02],\n",
       "        [-8.08854814e-04, -7.59355507e-02, -4.76031523e-01, ...,\n",
       "         -5.39194841e-03,  7.65120324e-01, -4.16305685e-02],\n",
       "        ...,\n",
       "        [-8.08854814e-04, -5.69966026e-02, -8.69632966e-01, ...,\n",
       "         -5.14896538e-03, -1.86907921e-01, -4.95096807e-02],\n",
       "        [ 5.08179321e-01, -6.38478366e-02,  3.79690673e-03, ...,\n",
       "         -5.88598781e-03,  4.32983884e-03, -4.76523928e-02],\n",
       "        [-5.90354960e-01, -6.59756911e-02,  8.78186432e-01, ...,\n",
       "         -5.81703578e-03, -5.30489234e-02, -4.46796282e-02]],\n",
       "\n",
       "       [[ 2.26353003e-02, -8.62495823e-02,  4.22113305e-01, ...,\n",
       "         -5.79715810e-03,  6.30304987e-01, -5.21399610e-02],\n",
       "        [ 9.68778120e-01, -1.59098430e-02, -2.05204374e-01, ...,\n",
       "         -5.88547830e-03,  7.13197914e-01, -4.55689899e-02],\n",
       "        [ 8.43075617e-01, -7.18234248e-02,  3.17433457e-01, ...,\n",
       "         -5.88451876e-03,  6.70971486e-01, -3.34767919e-02],\n",
       "        ...,\n",
       "        [-3.08333290e-01, -8.16219529e-02, -1.01269906e-01, ...,\n",
       "         -5.86990123e-03, -3.30234824e-01, -5.24595852e-02],\n",
       "        [-3.52401112e-01, -2.62865923e-02, -2.06290924e-01, ...,\n",
       "         -5.05062826e-03, -1.33444665e+00, -4.76158757e-02],\n",
       "        [-5.80097402e-01, -8.16757600e-02, -1.15216467e+00, ...,\n",
       "         -5.87041145e-03,  4.02395695e-01, -3.33076555e-02]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77922"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(np.array(train_y))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77922, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(np.reshape(train_y,(np.shape(train_y)[0],1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
